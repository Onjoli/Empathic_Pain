{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nilearn nibabel pandas matplotlib\n",
    "%pip install --upgrade nilearn\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nilearn\n",
    "import glob\n",
    "import re\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.image import load_img\n",
    "from nilearn.plotting import plot_epi, plot_design_matrix, plot_contrast_matrix, plot_stat_map\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.contrasts import compute_contrast\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.plotting import plot_stat_map\n",
    "from nilearn.reporting import get_clusters_table\n",
    "from nilearn.image import coord_transform\n",
    "from nilearn.image import resample_to_img, load_img\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99be8030",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nilearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f7f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Paths\n",
    "func_dir = '/Users/onjolikrywiak/Desktop/BrainHack/sub-001/func'\n",
    "reg_dir = '/Users/onjolikrywiak/Desktop/BrainHack/events/sub-001/regressors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Grab only the Lin2009cAsym bold files\n",
    "pattern   = os.path.join(func_dir, '*MNI152NLin2009cAsym*_bold.nii*')\n",
    "nii_files = sorted(glob.glob(pattern))\n",
    "print(\"Found bold files:\", nii_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a101f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Loop & pair each with its confounds\n",
    "for nii_path in nii_files:\n",
    "    basename = os.path.basename(nii_path)\n",
    "    \n",
    "    # Extract subj_task and run number, e.g. \"sub-001_task-empathy\" + \"run-01\"\n",
    "    m = re.match(r'(sub-[^_]+_task-[^_]+).*?(run-\\d+)', basename)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Can't parse subject/task/run from {basename}\")\n",
    "    subj_task = m.group(1)\n",
    "    run       = m.group(2)\n",
    "    \n",
    "    # Build confounds filename: sub-001_task-empathy_run-01_confounds.txt\n",
    "    conf_name = f\"{subj_task}_{run}_confounds.txt\"\n",
    "    conf_path = os.path.join(reg_dir, conf_name)\n",
    "    if not os.path.exists(conf_path):\n",
    "        raise FileNotFoundError(f\"Confounds file not found: {conf_path}\")\n",
    "    \n",
    "    # Load the bold image\n",
    "    img  = nib.load(nii_path)\n",
    "    data = img.get_fdata()\n",
    "    print(f\"{basename} → image shape {data.shape}\")\n",
    "    \n",
    "    # Load the confounds\n",
    "    # adjust sep if whitespace-delimited; here we assume tab-delimited\n",
    "    conf_df = pd.read_csv(conf_path, sep='\\t', header=None)\n",
    "    print(f\"{conf_name} → confounds shape {conf_df.shape}\")\n",
    "    \n",
    "    # Assign to run-specific variables\n",
    "    if run == 'run-01':\n",
    "        img1, data1, path1, conf1 = img, data, nii_path, conf_df\n",
    "    elif run == 'run-02':\n",
    "        img2, data2, path2, conf2 = img, data, nii_path, conf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ba4a4d",
   "metadata": {},
   "source": [
    "### Trim 3 timepoints from the beginning and end of BOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d42ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim 3 timepoints from the beginning and end of BOLD\n",
    "trim = 3\n",
    "if data.shape[-1] > 2 * trim:\n",
    "    data = data[..., trim:-trim]\n",
    "    print(f\"Trimmed BOLD shape: {data.shape}\")\n",
    "else:\n",
    "    raise ValueError(\"Not enough timepoints to trim 3 from each end.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e4623",
   "metadata": {},
   "source": [
    "### Check to see if BOLD and confounds are the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722dd98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"BOLD timepoints: {data.shape[-1]}\")\n",
    "print(f\"Confounds timepoints: {conf_df.shape[0]}\")\n",
    "\n",
    "if data.shape[-1] == conf_df.shape[0]:\n",
    "    print(\"BOLD and confounds are aligned!\")\n",
    "else:\n",
    "    print(\"Warning: BOLD and confounds are NOT aligned!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6f44c6",
   "metadata": {},
   "source": [
    "## Generate a Z-Map for One Trial Type (Single Subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Parse your custom events file\n",
    "events_txt = '/Users/onjolikrywiak/Desktop/BrainHack/events/sub-001/regressors/sub-001_task-empathy_timing-selfpain.txt'\n",
    "with open(events_txt) as f:\n",
    "    line = f.readline().strip()\n",
    "pairs = line.split('\\t')\n",
    "\n",
    "# Build events DataFrame\n",
    "onsets = []\n",
    "durations = []\n",
    "for pair in pairs:\n",
    "    onset, duration = pair.split(':')\n",
    "    onsets.append(float(onset))\n",
    "    durations.append(float(duration))\n",
    "events = pd.DataFrame({\n",
    "    'onset': onsets,\n",
    "    'duration': durations,\n",
    "    'trial_type': 'selfpain'  # or another label if needed\n",
    "})\n",
    "\n",
    "# 2. Fit the GLM (no confounds)\n",
    "fmri_glm = FirstLevelModel(\n",
    "    t_r=2.0,  # set your TR\n",
    "    noise_model='ar1',\n",
    "    standardize=True,\n",
    "    hrf_model='spm',\n",
    "    drift_model='cosine'\n",
    ")\n",
    "fmri_glm = fmri_glm.fit(img, events=events)\n",
    "\n",
    "# 3. Inspect design matrix columns\n",
    "print(\"Design matrix columns:\", fmri_glm.design_matrices_[0].columns.tolist())\n",
    "\n",
    "# 4. Define and compute the contrast\n",
    "contrast_name = 'selfpain'\n",
    "if contrast_name in fmri_glm.design_matrices_[0].columns:\n",
    "    contrast_vec = (fmri_glm.design_matrices_[0].columns == contrast_name).astype(int)\n",
    "    z_map = fmri_glm.compute_contrast(contrast_vec, output_type='z_score')\n",
    "\n",
    "    # 5. Plot the result\n",
    "    plot_stat_map(z_map, title=f'{contrast_name} > baseline', threshold=3.1)\n",
    "else:\n",
    "    print(f\"Contrast '{contrast_name}' not found in design matrix columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4938f232",
   "metadata": {},
   "source": [
    "## Generate Z-Maps for All Trial Types (Single Subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31da35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your regressors folder\n",
    "reg_dir = '/Users/onjolikrywiak/Desktop/BrainHack/events/sub-001/regressors'\n",
    "\n",
    "# Find all timing files in the folder\n",
    "event_files = glob.glob(os.path.join(reg_dir, 'sub-001_task-empathy_timing-*.txt'))\n",
    "\n",
    "for events_txt in event_files:\n",
    "    # Extract trial type from filename\n",
    "    basename = os.path.basename(events_txt)\n",
    "    trial_type = basename.split('timing-')[1].replace('.txt', '')\n",
    "\n",
    "    # Parse the custom events file\n",
    "    with open(events_txt) as f:\n",
    "        line = f.readline().strip()\n",
    "    pairs = line.split('\\t')\n",
    "\n",
    "    # Build events DataFrame\n",
    "    onsets = []\n",
    "    durations = []\n",
    "    for pair in pairs:\n",
    "        onset, duration = pair.split(':')\n",
    "        onsets.append(float(onset))\n",
    "        durations.append(float(duration))\n",
    "    events = pd.DataFrame({\n",
    "        'onset': onsets,\n",
    "        'duration': durations,\n",
    "        'trial_type': trial_type\n",
    "    })\n",
    "\n",
    "    # Fit the GLM (no confounds)\n",
    "    fmri_glm = FirstLevelModel(\n",
    "        t_r=2.0,\n",
    "        noise_model='ar1',\n",
    "        standardize=True,\n",
    "        hrf_model='spm',\n",
    "        drift_model='cosine'\n",
    "    )\n",
    "    fmri_glm = fmri_glm.fit(img, events=events)\n",
    "\n",
    "    # Inspect design matrix columns\n",
    "    print(f\"Design matrix columns for {trial_type}:\", fmri_glm.design_matrices_[0].columns.tolist())\n",
    "\n",
    "    # Define and compute the contrast\n",
    "    contrast_name = trial_type\n",
    "    if contrast_name in fmri_glm.design_matrices_[0].columns:\n",
    "        contrast_vec = (fmri_glm.design_matrices_[0].columns == contrast_name).astype(int)\n",
    "        z_map = fmri_glm.compute_contrast(contrast_vec, output_type='z_score')\n",
    "\n",
    "        # Plot the result\n",
    "        plot_stat_map(z_map, title=f'{contrast_name} > baseline', threshold=3.1)\n",
    "    else:\n",
    "        print(f\"Contrast '{contrast_name}' not found in design matrix columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647568df",
   "metadata": {},
   "source": [
    "## Generate Z-Maps for All Trial Types (All Subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23876b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/onjolikrywiak/Desktop/BrainHack'\n",
    "output_dir = os.path.join(base_dir, 'outputs')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "subjects = sorted([d for d in os.listdir(base_dir) if d.startswith('sub-')])[36:]\n",
    "print(\"Subjects found:\", subjects)\n",
    "\n",
    "for subj in subjects:\n",
    "    print(\"Processing subject:\", subj)\n",
    "    func_dir = os.path.join(base_dir, subj, 'func')\n",
    "    reg_dir = os.path.join(base_dir, 'events', subj, 'regressors')\n",
    "    nii_files = sorted(glob.glob(os.path.join(func_dir, '*MNI152NLin2009cAsym*_bold.nii*')))\n",
    "    print(f\"Subject: {subj}, nii_files: {nii_files}\")\n",
    "    \n",
    "    for nii_path in nii_files:\n",
    "        img = nib.load(nii_path)\n",
    "        basename = os.path.basename(nii_path)\n",
    "        subj_task_match = re.match(r'(sub-[^_]+_task-[^_]+)', basename)\n",
    "        if not subj_task_match:\n",
    "            print(f\"Could not parse subj_task from {basename}\")\n",
    "            continue\n",
    "        subj_task = subj_task_match.group(1)\n",
    "        \n",
    "        event_files = glob.glob(os.path.join(reg_dir, f'{subj_task}_timing-*.txt'))\n",
    "        print(f\"Subject: {subj}, event_files: {event_files}\")\n",
    "        for events_txt in event_files:\n",
    "            print(f\"Processing event file: {events_txt}\")\n",
    "            trial_type = os.path.basename(events_txt).split('timing-')[1].replace('.txt', '')\n",
    "            with open(events_txt) as f:\n",
    "                line = f.readline().strip()\n",
    "            pairs = line.split('\\t')\n",
    "            onsets, durations = [], []\n",
    "            for pair in pairs:\n",
    "                onset, duration = pair.split(':')\n",
    "                onsets.append(float(onset))\n",
    "                durations.append(float(duration))\n",
    "            events = pd.DataFrame({\n",
    "                'onset': onsets,\n",
    "                'duration': durations,\n",
    "                'trial_type': trial_type\n",
    "            })\n",
    "            \n",
    "            fmri_glm = FirstLevelModel(\n",
    "                t_r=2.0,\n",
    "                noise_model='ar1',\n",
    "                standardize=True,\n",
    "                hrf_model='spm',\n",
    "                drift_model='cosine'\n",
    "            )\n",
    "            fmri_glm = fmri_glm.fit(img, events=events)\n",
    "            print(f\"Subject: {subj}, Trial: {trial_type}\")\n",
    "            print(\"Design matrix columns:\", fmri_glm.design_matrices_[0].columns.tolist())\n",
    "            \n",
    "            contrast_name = trial_type\n",
    "            if contrast_name in fmri_glm.design_matrices_[0].columns:\n",
    "                contrast_vec = (fmri_glm.design_matrices_[0].columns == contrast_name).astype(int)\n",
    "                z_map = fmri_glm.compute_contrast(contrast_vec, output_type='z_score')\n",
    "                print(f\"About to plot and save for {subj} {trial_type}\")\n",
    "                zdata = z_map.get_fdata()\n",
    "                print(\"z_map min:\", np.nanmin(zdata), \"max:\", np.nanmax(zdata), \"mean:\", np.nanmean(zdata))\n",
    "                \n",
    "                # Save z-map NIfTI\n",
    "                zmap_nii = os.path.join(output_dir, f\"{subj}_{trial_type}_zmap.nii.gz\")\n",
    "                z_map.to_filename(zmap_nii)\n",
    "                \n",
    "                # Save plot as PNG\n",
    "                plot_png = os.path.join(output_dir, f\"{subj}_{trial_type}_zmap.png\")\n",
    "                disp = plot_stat_map(\n",
    "                    z_map,\n",
    "                    title=f'{subj} {trial_type} > baseline',\n",
    "                    threshold=3.1,\n",
    "                    output_file=plot_png\n",
    "                )\n",
    "                plt.close()  # Close the figure to avoid displaying in notebook\n",
    "                print(f\"Saved: {zmap_nii} and {plot_png}\")\n",
    "            else:\n",
    "                print(f\"Contrast '{contrast_name}' not found in design matrix columns for {subj}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc9cce",
   "metadata": {},
   "source": [
    "# Second-level (group) analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0d4a45",
   "metadata": {},
   "source": [
    "### Download/load atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443bf595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.datasets import fetch_atlas_harvard_oxford\n",
    "# Fetch the Harvard-Oxford atlas\n",
    "atlas = fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')\n",
    "atlas_img = load_img(atlas.maps)\n",
    "atlas_labels = list(atlas.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de67ce",
   "metadata": {},
   "source": [
    "### Run group level analysis with threshold and atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb37bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_types = [\"otherneutralanticipation\",\n",
    "               \"otherneutralcue\",\n",
    "               \"othernopain\",\n",
    "               \"othernopainrest\",\n",
    "               \"otherpain\",\n",
    "               \"otherpainanticipation\",\n",
    "               \"otherpaincue\",\n",
    "               \"otherpainrest\",\n",
    "               \"selfneutralanticipation\",\n",
    "               \"selfneutralcue\",\n",
    "               \"selfnopain\",\n",
    "               \"selfnopainrest\",\n",
    "               \"selfpain\",\n",
    "               \"selfpainanticipation\",\n",
    "               \"selfpainrest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial_type in trial_types:\n",
    "    zmap_files = sorted(glob.glob(f'/Users/onjolikrywiak/Desktop/BrainHack/outputs/sub-*_{trial_type}_zmap.nii.gz'))\n",
    "    if not zmap_files:\n",
    "        print(f\"No zmaps found for {trial_type}, skipping.\")\n",
    "        continue\n",
    "    zmap_imgs = [load_img(f) for f in zmap_files]\n",
    "    print(f\"Found zmaps for {trial_type}:\", zmap_files)\n",
    "\n",
    "    # Second-level analysis\n",
    "    n_subs = len(zmap_imgs)\n",
    "    design_matrix = pd.DataFrame([1] * n_subs, columns=['intercept'])\n",
    "    second_level_model = SecondLevelModel()\n",
    "    second_level_model = second_level_model.fit(zmap_imgs, design_matrix=design_matrix)\n",
    "    zmap_group = second_level_model.compute_contrast('intercept', output_type='z_score')\n",
    "\n",
    "    from nilearn.glm import threshold_stats_img\n",
    "    zmap_group = second_level_model.compute_contrast('intercept', output_type='z_score')\n",
    "    \n",
    "    # FDR correction ## Activation is too weak to survive FDR or FWE correction\n",
    "    #thresholded_map, threshold = threshold_stats_img(\n",
    "    #    zmap_group, alpha=0.1, height_control='fdr'\n",
    "    #    )\n",
    "    #print(f\"FDR threshold used: {threshold}\")\n",
    "\n",
    "    # Plot and save\n",
    "    plot_stat_map(\n",
    "        zmap_group,\n",
    "        threshold=3.1,\n",
    "        title=f'Group-level {trial_type} z-map',\n",
    "        output_file=f'/Users/onjolikrywiak/Desktop/BrainHack/outputs/group_{trial_type}_zmap.png'\n",
    "    )\n",
    "    zmap_group.to_filename(f'/Users/onjolikrywiak/Desktop/BrainHack/outputs/group_{trial_type}_zmap.nii.gz')\n",
    "    print(f\"Saved group z-map for {trial_type}\")\n",
    "\n",
    "    # Get and save clusters table\n",
    "    table = get_clusters_table(zmap_group, stat_threshold=3.1)\n",
    "    \n",
    "    # Resample atlas to match your group z-map\n",
    "    resampled_atlas = resample_to_img(atlas_img, zmap_group, interpolation='nearest')\n",
    "    \n",
    "    def get_label_from_coords(coord):\n",
    "        from nilearn.image import coord_transform\n",
    "        import numpy as np\n",
    "        # Convert MNI coordinates to voxel indices\n",
    "        voxel_coords = np.round(coord_transform(*coord, np.linalg.inv(resampled_atlas.affine))).astype(int)\n",
    "        data = resampled_atlas.get_fdata()\n",
    "        try:\n",
    "            label_index = int(data[tuple(voxel_coords)])\n",
    "            if label_index > 0 and label_index < len(atlas_labels):\n",
    "                return atlas_labels[label_index]\n",
    "            else:\n",
    "                return 'Unknown'\n",
    "        except Exception:\n",
    "            return 'Unknown'\n",
    "        \n",
    "    # Add anatomical labels to the cluster table\n",
    "    if not table.empty and all(col in table.columns for col in ['X', 'Y', 'Z']):\n",
    "        table['peak_coord'] = list(zip(table['X'], table['Y'], table['Z']))\n",
    "        table['Region_Label'] = table['peak_coord'].apply(get_label_from_coords)\n",
    "    else:\n",
    "        table['peak_coord'] = [None] * len(table)\n",
    "        table['Region_Label'] = [None] * len(table)\n",
    "\n",
    "    # Save table to CSV\n",
    "    csv_path = f'/Users/onjolikrywiak/Desktop/BrainHack/outputs/group_{trial_type}_clusters.csv'\n",
    "    table.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved clusters table for {trial_type} to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61665cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial_type in trial_types:\n",
    "    zmap_files = sorted(glob.glob(f'/Users/onjolikrywiak/Desktop/BrainHack/outputs/sub-*_{trial_type}_zmap.nii.gz'))\n",
    "    if not zmap_files:\n",
    "        print(f\"No zmaps found for {trial_type}, skipping.\")\n",
    "        continue\n",
    "    zmap_imgs = [load_img(f) for f in zmap_files]\n",
    "    print(f\"Found zmaps for {trial_type}:\", zmap_files)\n",
    "\n",
    "    # Second-level analysis\n",
    "    n_subs = len(zmap_imgs)\n",
    "    design_matrix = pd.DataFrame([1] * n_subs, columns=['intercept'])\n",
    "    second_level_model = SecondLevelModel()\n",
    "    second_level_model = second_level_model.fit(zmap_imgs, design_matrix=design_matrix)\n",
    "    zmap_group = second_level_model.compute_contrast('intercept', output_type='z_score')\n",
    "\n",
    "    from nilearn.glm import threshold_stats_img\n",
    "    zmap_group = second_level_model.compute_contrast('intercept', output_type='z_score')\n",
    "    \n",
    "    # FDR correction ## Activation is too weak to survive FDR or FWE correction\n",
    "    #thresholded_map, threshold = threshold_stats_img(\n",
    "    #    zmap_group, alpha=0.1, height_control='fdr'\n",
    "    #    )\n",
    "    #print(f\"FDR threshold used: {threshold}\")\n",
    "\n",
    "    # Plot and save\n",
    "    plot_stat_map(\n",
    "        zmap_group,\n",
    "        threshold=3.1,\n",
    "        title=f'Group-level {trial_type} z-map',\n",
    "        output_file=f'/Users/onjolikrywiak/Desktop/BrainHack/outputs/group_{trial_type}_zmap.png'\n",
    "    )\n",
    "    zmap_group.to_filename(f'/Users/onjolikrywiak/Desktop/BrainHack/outputs/group_{trial_type}_zmap.nii.gz')\n",
    "    print(f\"Saved group z-map for {trial_type}\")\n",
    "\n",
    "    # Get and save clusters table\n",
    "    table = get_clusters_table(zmap_group, stat_threshold=3.1)\n",
    "    \n",
    "    # Resample atlas to match your group z-map\n",
    "    resampled_atlas = resample_to_img(atlas_img, zmap_group, interpolation='nearest')\n",
    "    \n",
    "    def get_label_from_coords(coord):\n",
    "        from nilearn.image import coord_transform\n",
    "        import numpy as np\n",
    "        # Convert MNI coordinates to voxel indices\n",
    "        voxel_coords = np.round(coord_transform(*coord, np.linalg.inv(resampled_atlas.affine))).astype(int)\n",
    "        data = resampled_atlas.get_fdata()\n",
    "        try:\n",
    "            label_index = int(data[tuple(voxel_coords)])\n",
    "            if label_index > 0 and label_index < len(atlas_labels):\n",
    "                return atlas_labels[label_index]\n",
    "            else:\n",
    "                return 'Unknown'\n",
    "        except Exception:\n",
    "            return 'Unknown'\n",
    "        \n",
    "    # Add anatomical labels to the cluster table\n",
    "    if not table.empty and all(col in table.columns for col in ['X', 'Y', 'Z']):\n",
    "        table['peak_coord'] = list(zip(table['X'], table['Y'], table['Z']))\n",
    "        table['Region_Label'] = table['peak_coord'].apply(get_label_from_coords)\n",
    "    else:\n",
    "        table['peak_coord'] = [None] * len(table)\n",
    "        table['Region_Label'] = [None] * len(table)\n",
    "\n",
    "    # Save table to CSV\n",
    "    csv_path = f'/Users/onjolikrywiak/Desktop/BrainHack/outputs/group_{trial_type}_clusters.csv'\n",
    "    table.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved clusters table for {trial_type} to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56538dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not process /Users/onjolikrywiak/Desktop/BrainHack/outputs/group_otherpaincue_clusters.csv: [Errno 2] No such file or directory: '/Users/onjolikrywiak/Desktop/BrainHack/outputs/group_otherpaincue_clusters.csv'\n",
      "\n",
      "otherneutralanticipation:\n",
      "  Superior Temporal Gyrus, posterior division: 1 clusters\n",
      "  Planum Temporale: 3 clusters\n",
      "  Unknown: 14 clusters\n",
      "  Superior Parietal Lobule: 1 clusters\n",
      "  Middle Frontal Gyrus: 3 clusters\n",
      "  Superior Frontal Gyrus: 1 clusters\n",
      "  Precentral Gyrus: 1 clusters\n",
      "  Parietal Opercular Cortex: 1 clusters\n",
      "  Postcentral Gyrus: 1 clusters\n",
      "  Temporal Pole: 1 clusters\n",
      "  Supramarginal Gyrus, posterior division: 2 clusters\n",
      "  Inferior Temporal Gyrus, temporooccipital part: 1 clusters\n",
      "  Parahippocampal Gyrus, posterior division: 1 clusters\n",
      "\n",
      "otherneutralcue:\n",
      "  Superior Parietal Lobule: 1 clusters\n",
      "  Unknown: 7 clusters\n",
      "  Lateral Occipital Cortex, inferior division: 1 clusters\n",
      "  Frontal Opercular Cortex: 1 clusters\n",
      "  Temporal Pole: 1 clusters\n",
      "  Middle Frontal Gyrus: 2 clusters\n",
      "  Precentral Gyrus: 1 clusters\n",
      "  Superior Temporal Gyrus, posterior division: 1 clusters\n",
      "\n",
      "othernopain:\n",
      "  Frontal Pole: 3 clusters\n",
      "  Unknown: 51 clusters\n",
      "  Supramarginal Gyrus, posterior division: 3 clusters\n",
      "  Lateral Occipital Cortex, superior division: 8 clusters\n",
      "  Angular Gyrus: 6 clusters\n",
      "  Superior Temporal Gyrus, posterior division: 6 clusters\n",
      "  Inferior Frontal Gyrus, pars opercularis: 2 clusters\n",
      "  Middle Frontal Gyrus: 3 clusters\n",
      "  Paracingulate Gyrus: 1 clusters\n",
      "  Superior Frontal Gyrus: 2 clusters\n",
      "  Heschl's Gyrus (includes H1 and H2): 1 clusters\n",
      "  Planum Temporale: 3 clusters\n",
      "  Superior Parietal Lobule: 1 clusters\n",
      "  Middle Temporal Gyrus, posterior division: 3 clusters\n",
      "  Precentral Gyrus: 3 clusters\n",
      "  Planum Polare: 1 clusters\n",
      "  Middle Temporal Gyrus, temporooccipital part: 7 clusters\n",
      "  Inferior Frontal Gyrus, pars triangularis: 1 clusters\n",
      "  Cingulate Gyrus, posterior division: 1 clusters\n",
      "  Occipital Pole: 1 clusters\n",
      "\n",
      "othernopainrest:\n",
      "  Precentral Gyrus: 5 clusters\n",
      "  Unknown: 47 clusters\n",
      "  Lateral Occipital Cortex, superior division: 14 clusters\n",
      "  Lateral Occipital Cortex, inferior division: 2 clusters\n",
      "  Cuneal Cortex: 4 clusters\n",
      "  Temporal Pole: 2 clusters\n",
      "  Insular Cortex: 3 clusters\n",
      "  Postcentral Gyrus: 10 clusters\n",
      "  Middle Temporal Gyrus, anterior division: 1 clusters\n",
      "  Middle Temporal Gyrus, temporooccipital part: 1 clusters\n",
      "  Central Opercular Cortex: 1 clusters\n",
      "  Frontal Pole: 1 clusters\n",
      "  Temporal Occipital Fusiform Cortex: 3 clusters\n",
      "  Inferior Temporal Gyrus, posterior division: 1 clusters\n",
      "  Paracingulate Gyrus: 1 clusters\n",
      "  Inferior Temporal Gyrus, anterior division: 2 clusters\n",
      "  Lingual Gyrus: 1 clusters\n",
      "  Frontal Orbital Cortex: 1 clusters\n",
      "  Inferior Temporal Gyrus, temporooccipital part: 2 clusters\n",
      "  Occipital Pole: 1 clusters\n",
      "  Juxtapositional Lobule Cortex (formerly Supplementary Motor Cortex): 1 clusters\n",
      "  Superior Parietal Lobule: 1 clusters\n",
      "\n",
      "otherpain:\n",
      "  Unknown: 29 clusters\n",
      "  Precuneous Cortex: 1 clusters\n",
      "  Superior Parietal Lobule: 2 clusters\n",
      "  Supramarginal Gyrus, anterior division: 4 clusters\n",
      "  Middle Frontal Gyrus: 1 clusters\n",
      "  Lateral Occipital Cortex, superior division: 1 clusters\n",
      "  Inferior Frontal Gyrus, pars triangularis: 1 clusters\n",
      "  Lingual Gyrus: 1 clusters\n",
      "  Parietal Opercular Cortex: 1 clusters\n",
      "  Parahippocampal Gyrus, anterior division: 1 clusters\n",
      "  Lateral Occipital Cortex, inferior division: 2 clusters\n",
      "  Temporal Fusiform Cortex, posterior division: 1 clusters\n",
      "  Superior Frontal Gyrus: 1 clusters\n",
      "  Cingulate Gyrus, anterior division: 1 clusters\n",
      "\n",
      "otherpainanticipation:\n",
      "  Paracingulate Gyrus: 1 clusters\n",
      "  Unknown: 13 clusters\n",
      "  Superior Frontal Gyrus: 1 clusters\n",
      "  Lateral Occipital Cortex, inferior division: 2 clusters\n",
      "  Supramarginal Gyrus, posterior division: 1 clusters\n",
      "  Insular Cortex: 1 clusters\n",
      "  Frontal Orbital Cortex: 1 clusters\n",
      "  Temporal Pole: 1 clusters\n",
      "  Subcallosal Cortex: 1 clusters\n",
      "  Temporal Fusiform Cortex, posterior division: 1 clusters\n",
      "  Postcentral Gyrus: 1 clusters\n",
      "  Frontal Pole: 1 clusters\n",
      "  Juxtapositional Lobule Cortex (formerly Supplementary Motor Cortex): 1 clusters\n",
      "\n",
      "otherpainrest:\n",
      "  Precuneous Cortex: 1 clusters\n",
      "  Occipital Pole: 6 clusters\n",
      "  Unknown: 50 clusters\n",
      "  Planum Temporale: 3 clusters\n",
      "  Intracalcarine Cortex: 2 clusters\n",
      "  Paracingulate Gyrus: 2 clusters\n",
      "  Precentral Gyrus: 1 clusters\n",
      "  Frontal Orbital Cortex: 1 clusters\n",
      "  Angular Gyrus: 6 clusters\n",
      "  Lateral Occipital Cortex, superior division: 3 clusters\n",
      "  Postcentral Gyrus: 1 clusters\n",
      "  Lingual Gyrus: 3 clusters\n",
      "  Cuneal Cortex: 2 clusters\n",
      "  Frontal Pole: 6 clusters\n",
      "  Cingulate Gyrus, posterior division: 3 clusters\n",
      "  Central Opercular Cortex: 1 clusters\n",
      "  Lateral Occipital Cortex, inferior division: 4 clusters\n",
      "  Supramarginal Gyrus, posterior division: 1 clusters\n",
      "  Middle Temporal Gyrus, posterior division: 1 clusters\n",
      "  Temporal Occipital Fusiform Cortex: 1 clusters\n",
      "  Occipital Fusiform Gyrus: 1 clusters\n",
      "\n",
      "selfneutralanticipation:\n",
      "  Unknown: 28 clusters\n",
      "  Middle Temporal Gyrus, posterior division: 2 clusters\n",
      "  Planum Temporale: 1 clusters\n",
      "  Precentral Gyrus: 4 clusters\n",
      "  Central Opercular Cortex: 2 clusters\n",
      "  Superior Temporal Gyrus, posterior division: 6 clusters\n",
      "  Middle Frontal Gyrus: 3 clusters\n",
      "  Supramarginal Gyrus, posterior division: 2 clusters\n",
      "  Temporal Fusiform Cortex, posterior division: 1 clusters\n",
      "  Middle Temporal Gyrus, anterior division: 1 clusters\n",
      "  Lingual Gyrus: 1 clusters\n",
      "  Postcentral Gyrus: 2 clusters\n",
      "  Frontal Orbital Cortex: 1 clusters\n",
      "  Angular Gyrus: 1 clusters\n",
      "  Occipital Pole: 2 clusters\n",
      "\n",
      "selfneutralcue:\n",
      "  Lateral Occipital Cortex, inferior division: 6 clusters\n",
      "  Unknown: 10 clusters\n",
      "  Frontal Pole: 1 clusters\n",
      "  Lateral Occipital Cortex, superior division: 2 clusters\n",
      "  Superior Frontal Gyrus: 1 clusters\n",
      "  Middle Temporal Gyrus, temporooccipital part: 1 clusters\n",
      "  Postcentral Gyrus: 2 clusters\n",
      "  Precuneous Cortex: 1 clusters\n",
      "  Temporal Pole: 1 clusters\n",
      "  Occipital Pole: 1 clusters\n",
      "  Temporal Occipital Fusiform Cortex: 1 clusters\n",
      "  Supramarginal Gyrus, posterior division: 1 clusters\n",
      "  Central Opercular Cortex: 1 clusters\n",
      "  Superior Parietal Lobule: 1 clusters\n",
      "\n",
      "selfnopain:\n",
      "  Middle Temporal Gyrus, posterior division: 1 clusters\n",
      "  Unknown: 16 clusters\n",
      "  Precentral Gyrus: 2 clusters\n",
      "  Supramarginal Gyrus, posterior division: 1 clusters\n",
      "  Middle Frontal Gyrus: 1 clusters\n",
      "  Frontal Pole: 4 clusters\n",
      "  Superior Temporal Gyrus, anterior division: 1 clusters\n",
      "  Cuneal Cortex: 2 clusters\n",
      "  Superior Temporal Gyrus, posterior division: 1 clusters\n",
      "  Central Opercular Cortex: 1 clusters\n",
      "  Inferior Temporal Gyrus, anterior division: 1 clusters\n",
      "\n",
      "selfnopainrest:\n",
      "  Temporal Pole: 2 clusters\n",
      "  Unknown: 31 clusters\n",
      "  Planum Polare: 1 clusters\n",
      "  Middle Temporal Gyrus, temporooccipital part: 1 clusters\n",
      "  Parietal Opercular Cortex: 1 clusters\n",
      "  Frontal Pole: 2 clusters\n",
      "  Middle Temporal Gyrus, posterior division: 1 clusters\n",
      "  Superior Parietal Lobule: 1 clusters\n",
      "  Lateral Occipital Cortex, inferior division: 1 clusters\n",
      "\n",
      "selfpain:\n",
      "  Lateral Occipital Cortex, inferior division: 39 clusters\n",
      "  Lateral Occipital Cortex, superior division: 50 clusters\n",
      "  Unknown: 116 clusters\n",
      "  Temporal Occipital Fusiform Cortex: 5 clusters\n",
      "  Postcentral Gyrus: 19 clusters\n",
      "  Middle Frontal Gyrus: 6 clusters\n",
      "  Middle Temporal Gyrus, temporooccipital part: 7 clusters\n",
      "  Frontal Pole: 19 clusters\n",
      "  Inferior Temporal Gyrus, temporooccipital part: 10 clusters\n",
      "  Superior Parietal Lobule: 16 clusters\n",
      "  Supramarginal Gyrus, anterior division: 11 clusters\n",
      "  Precentral Gyrus: 13 clusters\n",
      "  Occipital Pole: 7 clusters\n",
      "  Angular Gyrus: 4 clusters\n",
      "  Inferior Frontal Gyrus, pars triangularis: 1 clusters\n",
      "  Occipital Fusiform Gyrus: 7 clusters\n",
      "  Frontal Orbital Cortex: 1 clusters\n",
      "  Superior Frontal Gyrus: 9 clusters\n",
      "  Supramarginal Gyrus, posterior division: 7 clusters\n",
      "  Middle Temporal Gyrus, posterior division: 3 clusters\n",
      "  Central Opercular Cortex: 1 clusters\n",
      "  Heschl's Gyrus (includes H1 and H2): 2 clusters\n",
      "  Inferior Frontal Gyrus, pars opercularis: 3 clusters\n",
      "  Cingulate Gyrus, anterior division: 2 clusters\n",
      "  Cingulate Gyrus, posterior division: 1 clusters\n",
      "  Inferior Temporal Gyrus, anterior division: 1 clusters\n",
      "\n",
      "selfpainanticipation:\n",
      "  Middle Temporal Gyrus, anterior division: 1 clusters\n",
      "  Superior Frontal Gyrus: 2 clusters\n",
      "  Precentral Gyrus: 5 clusters\n",
      "  Temporal Occipital Fusiform Cortex: 3 clusters\n",
      "  Frontal Pole: 5 clusters\n",
      "  Postcentral Gyrus: 3 clusters\n",
      "  Supramarginal Gyrus, anterior division: 1 clusters\n",
      "  Unknown: 16 clusters\n",
      "  Angular Gyrus: 1 clusters\n",
      "  Cingulate Gyrus, anterior division: 3 clusters\n",
      "  Insular Cortex: 3 clusters\n",
      "  Frontal Opercular Cortex: 1 clusters\n",
      "  Frontal Orbital Cortex: 1 clusters\n",
      "  Occipital Fusiform Gyrus: 1 clusters\n",
      "  Inferior Temporal Gyrus, anterior division: 1 clusters\n",
      "  Lingual Gyrus: 1 clusters\n",
      "\n",
      "selfpainrest:\n",
      "  Postcentral Gyrus: 10 clusters\n",
      "  Precentral Gyrus: 8 clusters\n",
      "  Cingulate Gyrus, posterior division: 8 clusters\n",
      "  Middle Temporal Gyrus, posterior division: 6 clusters\n",
      "  Insular Cortex: 2 clusters\n",
      "  Unknown: 144 clusters\n",
      "  Planum Temporale: 4 clusters\n",
      "  Cuneal Cortex: 2 clusters\n",
      "  Lateral Occipital Cortex, superior division: 31 clusters\n",
      "  Frontal Pole: 10 clusters\n",
      "  Supramarginal Gyrus, posterior division: 8 clusters\n",
      "  Superior Temporal Gyrus, posterior division: 3 clusters\n",
      "  Temporal Occipital Fusiform Cortex: 3 clusters\n",
      "  Paracingulate Gyrus: 3 clusters\n",
      "  Angular Gyrus: 7 clusters\n",
      "  Precuneous Cortex: 13 clusters\n",
      "  Inferior Frontal Gyrus, pars opercularis: 2 clusters\n",
      "  Inferior Temporal Gyrus, temporooccipital part: 3 clusters\n",
      "  Occipital Pole: 7 clusters\n",
      "  Superior Parietal Lobule: 5 clusters\n",
      "  Superior Frontal Gyrus: 3 clusters\n",
      "  Middle Frontal Gyrus: 4 clusters\n",
      "  Lingual Gyrus: 3 clusters\n",
      "  Frontal Orbital Cortex: 4 clusters\n",
      "  Middle Temporal Gyrus, temporooccipital part: 5 clusters\n",
      "  Cingulate Gyrus, anterior division: 2 clusters\n",
      "  Lateral Occipital Cortex, inferior division: 7 clusters\n",
      "  Frontal Opercular Cortex: 2 clusters\n",
      "  Central Opercular Cortex: 1 clusters\n",
      "  Intracalcarine Cortex: 4 clusters\n",
      "  Occipital Fusiform Gyrus: 2 clusters\n",
      "  Supramarginal Gyrus, anterior division: 4 clusters\n",
      "  Planum Polare: 1 clusters\n",
      "  Inferior Frontal Gyrus, pars triangularis: 1 clusters\n",
      "  Heschl's Gyrus (includes H1 and H2): 2 clusters\n",
      "  Juxtapositional Lobule Cortex (formerly Supplementary Motor Cortex): 1 clusters\n",
      "Saved region summary to outputs/region_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from collections import Counter\n",
    "\n",
    "summary = {}\n",
    "\n",
    "# Loop through all cluster tables\n",
    "for trial_type in trial_types:\n",
    "    csv_path = f'/Users/onjolikrywiak/Desktop/BrainHack/outputs/group_{trial_type}_clusters.csv'\n",
    "    try:\n",
    "        table = pd.read_csv(csv_path)\n",
    "        # Count occurrences of each region label\n",
    "        region_counts = Counter(table['Region_Label'].dropna())\n",
    "        summary[trial_type] = dict(region_counts)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not process {csv_path}: {e}\")\n",
    "\n",
    "# Print summary for each trial type\n",
    "for trial_type, regions in summary.items():\n",
    "    print(f\"\\n{trial_type}:\")\n",
    "    for region, count in regions.items():\n",
    "        print(f\"  {region}: {count} clusters\")\n",
    "\n",
    "# Optionally, save the summary to a CSV\n",
    "summary_df = pd.DataFrame(summary).fillna(0).astype(int)\n",
    "summary_df.to_csv('/Users/onjolikrywiak/Desktop/BrainHack/outputs/region_summary.csv')\n",
    "print(\"Saved region summary to outputs/region_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62a566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
